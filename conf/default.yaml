# model section
retriever:
  _target_: goldenretriever.GoldenRetriever
  question_encoder: "riccorl/e5-base-v2-blink-1M-32words-windows"
  document_index:
    _target_: goldenretriever.indexers.inmemory.InMemoryDocumentIndex
    documents:
      _target_: goldenretriever.indexers.document.DocumentStore.from_file
      file_path: "/root/golden-retriever/data/entitylinking/documents.jsonl"
    metadata_fields:
      - "definition"
    separator: " <def> "
    device: "cuda"
    precision: "16"

# data section
train_dataset:
  _target_: goldenretriever.data.streaming_dataset.GoldenRetrieverStreamingDataset
  name: "train_dataset"
  local: "/root/golden-retriever/data/entitylinking/aida_32_tokens_topic/train.jsonl"
  shuffle: True # force shuffle True for training
  shuffle_seed: 42
  max_question_length: 64
  max_passage_length: 64
  batch_size: 32

val_dataset:
  - _target_: goldenretriever.data.streaming_dataset.GoldenRetrieverStreamingDataset
    name: "val_dataset"
    local: "/root/golden-retriever/data/entitylinking/aida_32_tokens_topic/val.jsonl"
    shuffle: True # force shuffle True for training
    shuffle_seed: 42
    max_question_length: 64
    max_passage_length: 64
    batch_size: 32

num_workers: 4

# optimizer section
optimizer: goldenretriever.pytorch_modules.optim.RAdamW
lr: 1e-5
weight_decay: 0.01
lr_scheduler: goldenretriever.pytorch_modules.scheduler.LinearScheduler
max_steps: 25_000
# max_epochs: 1
accumulate_grad_batches: 8
gradient_clip_val: 1.0
deterministic: True
num_sanity_val_steps: null

# compute section
micro_batch_size: 32
precision: 16
accelerator: "auto"
devices: 1
strategy: "auto"
# FSDP
# strategy:
#   _target_: lightning.pytorch.strategies.FSDPStrategy
#   sharding_strategy: "NO_SHARD"

# eval section
metric_to_monitor: "validate_recall@{top_k}"
monitor_mode: "max"
top_k: 100
# prediction section
prediction_batch_size: 128
# hard negatives section
max_hard_negatives_to_mine: 15
hard_negatives_threshold: 0.0
mine_hard_negatives_with_probability: 1.0

# early section
early_stopping: true
early_stopping_patience: 10
early_stopping_kwargs: null

# logging section
log_to_wandb: true
wandb_entity: null
wandb_experiment_name: "golden-retriever-default-aida"
wandb_project_name: "aida-e5-base-topics-from-blink-1M-32words-windows-streaming-cli"
wandb_online_mode: true
wandb_kwargs: null

# checkpointing section
model_checkpointing: true
checkpoint_dir: "checkpoints"
save_top_k: 1
checkpoint_kwargs: null
resume_from_checkpoint_path: null

# additional kwargs to pass to the Lightning Trainer
lightning_trainer_kwargs: null

# other parameters
seed: 42
float32_matmul_precision: "medium"

# to use for Trainer.test()
test_kwargs: null